最大熵模型被评价为形式最优美，实现最复杂的机器学习模型之一。由最大熵原理推导而得。

- 最大熵原理  
在所有可能的概率模型中，熵最大的模型为最好的模型。  
信息熵：H(p) = -sum P(x) log(P(x)), 0<=H(P)<=log|x|.  
条件熵：H(y|X) = -sum P(y|X) log(P(y|X))，这里的P(y|X)即为贝叶斯里要求的同一个东西，两者由此可联系起来。  
![conditionalEntropy](https://user-images.githubusercontent.com/42667259/91316203-dadaea00-e7b8-11ea-8f88-1abb9caa0583.jpg)

- 最大熵模型定义？  
https://zhuanlan.zhihu.com/p/29978153  
最大熵原理是统计学习的一般原理,将它应用到分类就得到了最大熵模型。    
假设分类模型是一个条件概率分布P(Y|X),X表示输入,Y表示输出。这个模型表示的是对于给定的输入X,以条件概率P(Y|X)输出Y。  
给定数据集T,我们的目标就是根据最大熵原理选择一个最优的分类器。  
已知特征函数和约束条件,我们将熵的概念应用到条件分布上面去。我们采用条件熵。   
![conditionalEntropy_2](https://user-images.githubusercontent.com/42667259/91316208-dc0c1700-e7b8-11ea-9c35-80f2d3405b71.jpg)   
至此,我们可以给出最大熵模型的完整描述了。对于给定的数据集T,特征函数f i (x,y),i=1,…,n,最大熵模型就是求解模型集合C中条件熵最大的模型H(p)，也就是最小化-H(p):  
![maxHp](https://user-images.githubusercontent.com/42667259/91316763-81bf8600-e7b9-11ea-9030-8d18aadcd1a8.jpg)

- 最大熵模型学习？  
最大熵模型的学习过程就是求解最大熵模型的过程。求解上图中约束最优化问题(3.12),(3.13)所得的解就是最大熵模型学习的解。思路如下: 利用拉格朗日乘子法将最大熵模型由一个带约束的最优化问题转化为一个与之等价的无约束的最优化问题,它是一个min max问题。利用对偶问题的等价性,将原始问题转换为一个max min问题。  
具体步骤见https://zhuanlan.zhihu.com/p/29978153  
