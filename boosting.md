介绍一下Boosting的思想  
串行的方式训练基分类器，各分类器之间有依赖。每次训练时，对前一层基分类器分错的样本给与更高的权重

1. bagging和boosting区别，如下链接：
https://medium.com/@pkqiang49/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0-%E8%AF%A6%E8%A7%A3-bagging-boosting-%E4%BB%A5%E5%8F%8A%E4%BB%96%E4%BB%AC%E7%9A%84-4-%E7%82%B9%E5%8C%BA%E5%88%AB-6e3c72df05b8
答：不同于bagging相当于平均每颗决策树的权重，boosting权重不同，是给预测好的高权重，不好的低权重，同时还要在训练时提高易分错样本的权重。1）通过加法模型将基础模型进行线性的组合。2）每一轮训练都提升那些错误率小的基础模型权重，同时减小错误率高的模型权重。3）在每一轮改变训练数据的权值或概率分布，通过提高那些在前一轮被弱分类器分错样例的权值，减小前一轮分对样例的权值，来使得分类器对误分的数据有较好的效果。
