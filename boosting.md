##### boost类方法进化史：Adaboost->gbdt->xgboost->lightgbm。

##### 1. Adaboost
- 介绍一下Boosting的思想？  
串行的方式训练基分类器，各分类器之间有依赖。每次训练时，对前一层基分类器分错的样本给与更高的权重  
不同于bagging相当于平均每颗决策树的权重，boosting权重不同，是给预测好的高权重，不好的低权重，同时还要在训练时提高易分错样本的权重。1）通过加法模型将基础模型进行线性的组合。2）每一轮训练都提升那些错误率小的基础模型权重，同时减小错误率高的模型权重。3）在每一轮改变训练数据的权值或概率分布，通过提高那些在前一轮被弱分类器分错样例的权值，减小前一轮分对样例的权值，来使得分类器对误分的数据有较好的效果。  
附： bagging和boosting区别？  
如下链接：https://medium.com/@pkqiang49/%E4%B8%80%E6%96%87%E7%9C%8B%E6%87%82%E9%9B%86%E6%88%90%E5%AD%A6%E4%B9%A0-%E8%AF%A6%E8%A7%A3-bagging-boosting-%E4%BB%A5%E5%8F%8A%E4%BB%96%E4%BB%AC%E7%9A%84-4-%E7%82%B9%E5%8C%BA%E5%88%AB-6e3c72df05b8

##### 2. gbdt
- gbdt的中的tree是什么tree？有什么特征？  
https://zhuanlan.zhihu.com/p/30654833  
答：是回归树。回归树总体流程类似于分类树，区别在于，回归树的每一个节点都会得一个预测值，以年龄为例，该预测值等于属于这个节点的所有人年龄的平均值。分枝时穷举每一个feature的每个阈值找最好的分割点，但衡量最好的标准不再是最大熵，而是最小化平方误差,MSE。

##### 3. xgboost   
- xgboost对比gbdt/boosting Tree有了哪些方向上的优化？  
https://zhuanlan.zhihu.com/p/56137208  
GBDT是基于boosting的思想，串行地构造多棵决策树来进行数据的预测，它是在损失函数所在的函数空间中做梯度下降，即把待求的决策树模型当作参数，每轮迭代都去拟合损失函数在当前模型下的负梯度，从而使得参数朝着最小化损失函数的方向更新。  
GBDT可以看作是AdaBoost的一个推广，AdaBoost是通过错分数据点来识别问题，通过调整错分数据点的权重来改进模型，GBDT是通过负梯度来识别问题，通过计算负梯度来改进模型，实际上，负梯度绝对值大的样例同样会在之后的训练中受到更大的关注，因为它造成的损失更容易在最后的损失函数中占很大的比重，因此，需要更多地偏向于它去减小损失。这也是GBDT和AdaBoost相似的一个点。  
xgboost是梯度提升树的一种高效系统实现，是对GBDT进一步的改进，包括对代价函数进行了二阶泰勒展开，在代价函数里加入了正则项，借鉴了随机森林的列采样方法，支持并行计算等  

##### 4. lightgbm
- LightGBM简介？   
LightGBM是一个实现GBDT算法的分布式高效框架。它通过leaf-wise分裂方法进行决策树的生成，通过基于直方图的算法寻找特征分割点，并支持并行学习，能够更高效的处理大数据，也得到了越来越广泛的应用。  
